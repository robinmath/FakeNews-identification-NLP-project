{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and evaluation using baseline model\n",
    "\n",
    "In this section we will apply the traditional approach of feature engineering for text using Bag of Words normalised by the TF-IDF factor. We will analyse BoW features as uni-grams alone and also as a combination of uni-grams and bi-grams. The baseline model for evaluating the features will be a multinomial Naive Bayes prediction model.\n",
    "\n",
    "We will carry out the experiment using different combinations of input data from our baselined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('pickle_file','rb')\n",
    "df=pickle.load(pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('index',axis=1,inplace=True)\n",
    "df.drop('text',axis=1,inplace=True)\n",
    "df.drop('title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>fake</th>\n",
       "      <th>site_name</th>\n",
       "      <th>text_length</th>\n",
       "      <th>type</th>\n",
       "      <th>normal_text</th>\n",
       "      <th>proper_nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adj</th>\n",
       "      <th>ner</th>\n",
       "      <th>normal_title</th>\n",
       "      <th>adverbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080</td>\n",
       "      <td>True</td>\n",
       "      <td>735</td>\n",
       "      <td>723</td>\n",
       "      <td>19</td>\n",
       "      <td>[star, magazine, release, explosive, report, t...</td>\n",
       "      <td>[star, brad, pitt, bard, star, brad]</td>\n",
       "      <td>[release, come, learn, wish, remain, come, cla...</td>\n",
       "      <td>[explosive, pregnant, old, former, early, anon...</td>\n",
       "      <td>[star, brad pitt's, bard, star, brad]</td>\n",
       "      <td>[us, report, brad, pitt, s, secret, lover, pre...</td>\n",
       "      <td>[forward, allegedly, forward, effectively]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1898</td>\n",
       "      <td>True</td>\n",
       "      <td>358</td>\n",
       "      <td>4749</td>\n",
       "      <td>19</td>\n",
       "      <td>[early, year, buzz, around, megyn, kellys, mov...</td>\n",
       "      <td>[megyn, kellys, fox, news, nbc, fox, nbc, nbc,...</td>\n",
       "      <td>[buzz, move, get, break, capture, pay, turn, f...</td>\n",
       "      <td>[early, loud, insular, loyal, high, political,...</td>\n",
       "      <td>[fox news, nbc, fox, nbc, nbc, kellys, matt la...</td>\n",
       "      <td>[megyn, kelly, make, list, highest, pay, tv, h...</td>\n",
       "      <td>[typically, alike, nowhere, also, annually, ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>606</td>\n",
       "      <td>True</td>\n",
       "      <td>456</td>\n",
       "      <td>1673</td>\n",
       "      <td>19</td>\n",
       "      <td>[first, time, since, involvement, fatal, car, ...</td>\n",
       "      <td>[kenneth, mosher, april, bachelor, chris, soul...</td>\n",
       "      <td>[kill, speak, reveal, lean, read, click, overw...</td>\n",
       "      <td>[first, fatal, fellow, overwhelmed, full, fell...</td>\n",
       "      <td>[kenneth mosher, chris soules, chris soules, c...</td>\n",
       "      <td>[chris, soule, break, silence, fatal, accident...</td>\n",
       "      <td>[finally, extremely, together, well, previousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3791</td>\n",
       "      <td>True</td>\n",
       "      <td>1280</td>\n",
       "      <td>811</td>\n",
       "      <td>19</td>\n",
       "      <td>[heel, cute, last, long, selena, gomez, wear, ...</td>\n",
       "      <td>[selena, gomez, hotel, transylvania, selena, s...</td>\n",
       "      <td>[wear, keep, ditch, go, sign, add, ruin, top, ...</td>\n",
       "      <td>[cute, last, sparkly, mid, -, heel, red, baref...</td>\n",
       "      <td>[heels cute, selena gomez, hotel transylvania ...</td>\n",
       "      <td>[selena, gomez, go, barefoot, street, hotel, t...</td>\n",
       "      <td>[also, cashmere, frankly, kind, hey, still, tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3535</td>\n",
       "      <td>True</td>\n",
       "      <td>816</td>\n",
       "      <td>871</td>\n",
       "      <td>19</td>\n",
       "      <td>[jessica, simpsons, beloved, dog, daisy, snatc...</td>\n",
       "      <td>[jessica, simpsons, daisy, monday, simpson, tw...</td>\n",
       "      <td>[snatch, watch, happen, reveal, break, take, w...</td>\n",
       "      <td>[beloved, stunned, precious, right, front, sho...</td>\n",
       "      <td>[jessica simpsons, daisy, simpson, twitter, da...</td>\n",
       "      <td>[jessica, simpson, heartbroken, missing, dog]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authors  fake  site_name  text_length  type  \\\n",
       "0     1080  True        735          723    19   \n",
       "1     1898  True        358         4749    19   \n",
       "2      606  True        456         1673    19   \n",
       "3     3791  True       1280          811    19   \n",
       "4     3535  True        816          871    19   \n",
       "\n",
       "                                         normal_text  \\\n",
       "0  [star, magazine, release, explosive, report, t...   \n",
       "1  [early, year, buzz, around, megyn, kellys, mov...   \n",
       "2  [first, time, since, involvement, fatal, car, ...   \n",
       "3  [heel, cute, last, long, selena, gomez, wear, ...   \n",
       "4  [jessica, simpsons, beloved, dog, daisy, snatc...   \n",
       "\n",
       "                                        proper_nouns  \\\n",
       "0               [star, brad, pitt, bard, star, brad]   \n",
       "1  [megyn, kellys, fox, news, nbc, fox, nbc, nbc,...   \n",
       "2  [kenneth, mosher, april, bachelor, chris, soul...   \n",
       "3  [selena, gomez, hotel, transylvania, selena, s...   \n",
       "4  [jessica, simpsons, daisy, monday, simpson, tw...   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  [release, come, learn, wish, remain, come, cla...   \n",
       "1  [buzz, move, get, break, capture, pay, turn, f...   \n",
       "2  [kill, speak, reveal, lean, read, click, overw...   \n",
       "3  [wear, keep, ditch, go, sign, add, ruin, top, ...   \n",
       "4  [snatch, watch, happen, reveal, break, take, w...   \n",
       "\n",
       "                                                 adj  \\\n",
       "0  [explosive, pregnant, old, former, early, anon...   \n",
       "1  [early, loud, insular, loyal, high, political,...   \n",
       "2  [first, fatal, fellow, overwhelmed, full, fell...   \n",
       "3  [cute, last, sparkly, mid, -, heel, red, baref...   \n",
       "4  [beloved, stunned, precious, right, front, sho...   \n",
       "\n",
       "                                                 ner  \\\n",
       "0              [star, brad pitt's, bard, star, brad]   \n",
       "1  [fox news, nbc, fox, nbc, nbc, kellys, matt la...   \n",
       "2  [kenneth mosher, chris soules, chris soules, c...   \n",
       "3  [heels cute, selena gomez, hotel transylvania ...   \n",
       "4  [jessica simpsons, daisy, simpson, twitter, da...   \n",
       "\n",
       "                                        normal_title  \\\n",
       "0  [us, report, brad, pitt, s, secret, lover, pre...   \n",
       "1  [megyn, kelly, make, list, highest, pay, tv, h...   \n",
       "2  [chris, soule, break, silence, fatal, accident...   \n",
       "3  [selena, gomez, go, barefoot, street, hotel, t...   \n",
       "4      [jessica, simpson, heartbroken, missing, dog]   \n",
       "\n",
       "                                             adverbs  \n",
       "0         [forward, allegedly, forward, effectively]  \n",
       "1  [typically, alike, nowhere, also, annually, ac...  \n",
       "2  [finally, extremely, together, well, previousl...  \n",
       "3  [also, cashmere, frankly, kind, hey, still, tw...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14968 entries, 0 to 14967\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   authors       14968 non-null  int16 \n",
      " 1   fake          14968 non-null  bool  \n",
      " 2   site_name     14968 non-null  int16 \n",
      " 3   text_length   14968 non-null  int64 \n",
      " 4   type          14968 non-null  int8  \n",
      " 5   normal_text   14968 non-null  object\n",
      " 6   proper_nouns  14968 non-null  object\n",
      " 7   verbs         14968 non-null  object\n",
      " 8   adj           14968 non-null  object\n",
      " 9   ner           14968 non-null  object\n",
      " 10  normal_title  14968 non-null  object\n",
      " 11  adverbs       14968 non-null  object\n",
      "dtypes: bool(1), int16(2), int64(1), int8(1), object(7)\n",
      "memory usage: 1023.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=149) # skip if running sub prediction, start from C6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data - normal text\n",
    "\n",
    "### BoW with TF-IDF (uni-grams and bi-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      1.00      0.87      2268\n",
      "        True       1.00      0.03      0.06       726\n",
      "\n",
      "    accuracy                           0.77      2994\n",
      "   macro avg       0.88      0.52      0.46      2994\n",
      "weighted avg       0.82      0.77      0.67      2994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(input='content',strip_accents='unicode',lowercase=True,ngram_range=(1,2),max_df=1.0,min_df=1)),  \n",
    "    ('tfidf', TfidfTransformer()),  # BOW counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(df_train['normal_text'].apply(' '.join),df_train['fake'])\n",
    "predictions = pipeline.predict(df_test['normal_text'].apply(' '.join))\n",
    "print(classification_report(df_test['fake'],predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW with TF-IDF (only uni-grams)\n",
    "We can see the bi-grams are not having any positive impact. So for the rest of the section we will only consider uni-grams, since processing will also be cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      1.00      0.87      2268\n",
      "        True       0.98      0.09      0.16       726\n",
      "\n",
      "    accuracy                           0.78      2994\n",
      "   macro avg       0.88      0.54      0.51      2994\n",
      "weighted avg       0.82      0.78      0.70      2994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(input='content',strip_accents='unicode',lowercase=True,ngram_range=(1,1),max_df=1.0,min_df=1)),  \n",
    "    ('tfidf', TfidfTransformer()),  # BOW counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(df_train['normal_text'].apply(' '.join),df_train['fake'])\n",
    "predictions = pipeline.predict(df_test['normal_text'].apply(' '.join))\n",
    "print(classification_report(df_test['fake'],predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for bow, tf-idf transformers and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(in_text_series):\n",
    "    bow_transformer=CountVectorizer(input='content',strip_accents='unicode',lowercase=True,ngram_range=(1,1),max_df=1.0,min_df=1).fit(in_text_series.apply(' '.join))\n",
    "    text_bow = bow_transformer.transform(in_text_series.apply(' '.join))\n",
    "    tfidf_transformer = TfidfTransformer().fit(text_bow)\n",
    "    text_tfidf = tfidf_transformer.transform(text_bow)\n",
    "    return {'text_tfidf':text_tfidf, 'bow_transformer':bow_transformer, 'tfidf_transformer':tfidf_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip if running sub prediction, start from C6\n",
    "df_train_sub_features = df_train[['type', 'site_name', 'authors', 'text_length']].copy()\n",
    "df_test_sub_features = df_test[['type', 'site_name', 'authors', 'text_length']].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 1 (C1)- normalised text, authors, site_name, text_length, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_text_tfidf = get_tfidf(df_train['normal_text'])\n",
    "df_train_normal_text_tfidf = pd.DataFrame(normal_text_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C1 = pd.concat([df_train_normal_text_tfidf.reset_index(drop=True), df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C1_sm=scipy.sparse.csr_matrix(df_train_C1.values).copy() #sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = MultinomialNB().fit(df_train_C1_sm, df_train['fake'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_text_bow = normal_text_tfidf['bow_transformer'].transform(df_test['normal_text'].apply(' '.join))\n",
    "test_normal_text_tfidf = normal_text_tfidf['tfidf_transformer'].transform(test_normal_text_bow)\n",
    "df_test_normal_text_tfidf = pd.DataFrame(test_normal_text_tfidf.toarray())\n",
    "\n",
    "df_test_C1 = pd.concat([df_test_normal_text_tfidf.reset_index(drop=True), df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C1_sm=scipy.sparse.csr_matrix(df_test_C1.values).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.43      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C1_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 2 (C2)- normalised title, authors, site_name, text_length, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_title_tfidf = get_tfidf(df_train['normal_title'])\n",
    "df_train_normal_title_tfidf = pd.DataFrame(normal_title_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C2 = pd.concat([df_train_normal_title_tfidf.reset_index(drop=True), df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C2_sm=scipy.sparse.csr_matrix(df_train_C2.values).copy() #sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = MultinomialNB().fit(df_train_C2_sm, df_train['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_title_bow = normal_title_tfidf['bow_transformer'].transform(df_test['normal_title'].apply(' '.join))\n",
    "test_normal_title_tfidf = normal_title_tfidf['tfidf_transformer'].transform(test_normal_title_bow)\n",
    "df_test_normal_title_tfidf = pd.DataFrame(test_normal_title_tfidf.toarray())\n",
    "\n",
    "df_test_C2 = pd.concat([df_test_normal_title_tfidf.reset_index(drop=True), df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C2_sm=scipy.sparse.csr_matrix(df_test_C2.values).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.44      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C2_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 3 (C3)- proper nouns, verbs, adjectives, authors, site_name, text_length, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_nouns_tfidf = get_tfidf(df_train['proper_nouns'])\n",
    "verbs_tfidf = get_tfidf(df_train['verbs'])\n",
    "adj_tfidf = get_tfidf(df_train['adj'])\n",
    "\n",
    "df_train_proper_nouns_tfidf = pd.DataFrame(proper_nouns_tfidf['text_tfidf'].toarray())\n",
    "df_train_verbs_tfidf = pd.DataFrame(verbs_tfidf['text_tfidf'].toarray())\n",
    "df_train_adj_tfidf = pd.DataFrame(adj_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C3 = pd.concat([df_train_proper_nouns_tfidf.reset_index(drop=True),df_train_verbs_tfidf.reset_index(drop=True),df_train_adj_tfidf.reset_index(drop=True),df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C3_sm=scipy.sparse.csr_matrix(df_train_C3.values).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = MultinomialNB().fit(df_train_C3_sm, df_train['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proper_nouns_bow = proper_nouns_tfidf['bow_transformer'].transform(df_test['proper_nouns'].apply(' '.join))\n",
    "test_proper_nouns_tfidf = proper_nouns_tfidf['tfidf_transformer'].transform(test_proper_nouns_bow)\n",
    "df_test_proper_nouns_tfidf = pd.DataFrame(test_proper_nouns_tfidf.toarray())\n",
    "\n",
    "test_verbs_bow = verbs_tfidf['bow_transformer'].transform(df_test['verbs'].apply(' '.join))\n",
    "test_verbs_tfidf = verbs_tfidf['tfidf_transformer'].transform(test_verbs_bow)\n",
    "df_test_verbs_tfidf = pd.DataFrame(test_verbs_tfidf.toarray())\n",
    "\n",
    "test_adj_bow = adj_tfidf['bow_transformer'].transform(df_test['adj'].apply(' '.join))\n",
    "test_adj_tfidf = adj_tfidf['tfidf_transformer'].transform(test_adj_bow)\n",
    "df_test_adj_tfidf = pd.DataFrame(test_adj_tfidf.toarray())\n",
    "\n",
    "df_test_C3 = pd.concat([df_test_proper_nouns_tfidf.reset_index(drop=True),df_test_verbs_tfidf.reset_index(drop=True),df_test_adj_tfidf.reset_index(drop=True),df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C3_sm=scipy.sparse.csr_matrix(df_test_C3.values).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.43      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C3_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 4 (C4)- named entities, verbs, adjectives, authors, site_name, text_length, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tfidf = get_tfidf(df_train['ner'])\n",
    "verbs_tfidf = get_tfidf(df_train['verbs'])\n",
    "adj_tfidf = get_tfidf(df_train['adj'])\n",
    "\n",
    "df_train_ner_tfidf = pd.DataFrame(ner_tfidf['text_tfidf'].toarray())\n",
    "df_train_verbs_tfidf = pd.DataFrame(verbs_tfidf['text_tfidf'].toarray())\n",
    "df_train_adj_tfidf = pd.DataFrame(adj_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C4 = pd.concat([df_train_ner_tfidf.reset_index(drop=True),df_train_verbs_tfidf.reset_index(drop=True),df_train_adj_tfidf.reset_index(drop=True),df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C4_sm=scipy.sparse.csr_matrix(df_train_C4.values).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = MultinomialNB().fit(df_train_C4_sm, df_train['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ner_bow = ner_tfidf['bow_transformer'].transform(df_test['ner'].apply(' '.join))\n",
    "test_ner_tfidf = ner_tfidf['tfidf_transformer'].transform(test_ner_bow)\n",
    "df_test_ner_tfidf = pd.DataFrame(test_ner_tfidf.toarray())\n",
    "\n",
    "test_verbs_bow = verbs_tfidf['bow_transformer'].transform(df_test['verbs'].apply(' '.join))\n",
    "test_verbs_tfidf = verbs_tfidf['tfidf_transformer'].transform(test_verbs_bow)\n",
    "df_test_verbs_tfidf = pd.DataFrame(test_verbs_tfidf.toarray())\n",
    "\n",
    "test_adj_bow = adj_tfidf['bow_transformer'].transform(df_test['adj'].apply(' '.join))\n",
    "test_adj_tfidf = adj_tfidf['tfidf_transformer'].transform(test_adj_bow)\n",
    "df_test_adj_tfidf = pd.DataFrame(test_adj_tfidf.toarray())\n",
    "\n",
    "df_test_C4 = pd.concat([df_test_ner_tfidf.reset_index(drop=True),df_test_verbs_tfidf.reset_index(drop=True),df_test_adj_tfidf.reset_index(drop=True),df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C4_sm=scipy.sparse.csr_matrix(df_test_C4.values).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.43      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C4_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 5 (C5)- adverbs, verbs, adjectives, authors, site_name, text_length, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adverbs_tfidf = get_tfidf(df_train['adverbs'])\n",
    "verbs_tfidf = get_tfidf(df_train['verbs'])\n",
    "adj_tfidf = get_tfidf(df_train['adj'])\n",
    "\n",
    "df_train_adverbs_tfidf = pd.DataFrame(adverbs_tfidf['text_tfidf'].toarray())\n",
    "df_train_verbs_tfidf = pd.DataFrame(verbs_tfidf['text_tfidf'].toarray())\n",
    "df_train_adj_tfidf = pd.DataFrame(adj_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C5 = pd.concat([df_train_adverbs_tfidf.reset_index(drop=True),df_train_verbs_tfidf.reset_index(drop=True),df_train_adj_tfidf.reset_index(drop=True),df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C5_sm=scipy.sparse.csr_matrix(df_train_C5.values).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = MultinomialNB().fit(df_train_C5_sm, df_train['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adverbs_bow = adverbs_tfidf['bow_transformer'].transform(df_test['adverbs'].apply(' '.join))\n",
    "test_adverbs_tfidf = adverbs_tfidf['tfidf_transformer'].transform(test_adverbs_bow)\n",
    "df_test_adverbs_tfidf = pd.DataFrame(test_adverbs_tfidf.toarray())\n",
    "\n",
    "test_verbs_bow = verbs_tfidf['bow_transformer'].transform(df_test['verbs'].apply(' '.join))\n",
    "test_verbs_tfidf = verbs_tfidf['tfidf_transformer'].transform(test_verbs_bow)\n",
    "df_test_verbs_tfidf = pd.DataFrame(test_verbs_tfidf.toarray())\n",
    "\n",
    "test_adj_bow = adj_tfidf['bow_transformer'].transform(df_test['adj'].apply(' '.join))\n",
    "test_adj_tfidf = adj_tfidf['tfidf_transformer'].transform(test_adj_bow)\n",
    "df_test_adj_tfidf = pd.DataFrame(test_adj_tfidf.toarray())\n",
    "\n",
    "df_test_C5 = pd.concat([df_test_adverbs_tfidf.reset_index(drop=True),df_test_verbs_tfidf.reset_index(drop=True),df_test_adj_tfidf.reset_index(drop=True),df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C5_sm=scipy.sparse.csr_matrix(df_test_C5.values).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.43      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C5_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 2 (C2)- normalised title, authors, site_name, text_length, type with ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_title_tfidf = get_tfidf(df_train['normal_title'])\n",
    "df_train_normal_title_tfidf = pd.DataFrame(normal_title_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C2 = pd.concat([df_train_normal_title_tfidf.reset_index(drop=True), df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C2_sm=scipy.sparse.csr_matrix(df_train_C2.values).copy() #sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = ComplementNB().fit(df_train_C2_sm, df_train['fake']) # suited for imbalanced data sets as per documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_title_bow = normal_title_tfidf['bow_transformer'].transform(df_test['normal_title'].apply(' '.join))\n",
    "test_normal_title_tfidf = normal_title_tfidf['tfidf_transformer'].transform(test_normal_title_bow)\n",
    "df_test_normal_title_tfidf = pd.DataFrame(test_normal_title_tfidf.toarray())\n",
    "\n",
    "df_test_C2 = pd.concat([df_test_normal_title_tfidf.reset_index(drop=True), df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C2_sm=scipy.sparse.csr_matrix(df_test_C2.values).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.44      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C2_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complement NB is not having any better results than Multinomial NB. So we will not pursue this algorithm further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data Combination 6 (C6)- normalised title + Categorical Prediction (authors, site_name, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"]=df[\"type\"].astype('category')\n",
    "df[\"site_name\"]=df[\"site_name\"].astype('category')\n",
    "df[\"authors\"]=df[\"authors\"].astype('category')\n",
    "df_main, df_sub = train_test_split(df, test_size=0.33, random_state=149) # for sub modeling intermediate prediction\n",
    "\n",
    "df_train, df_test = train_test_split(df_sub, test_size=0.1, random_state=149) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_prediction_model = CategoricalNB().fit(df_train[['type', 'site_name', 'authors']], df_train['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.96      0.89       368\n",
      "        True       0.78      0.42      0.55       126\n",
      "\n",
      "    accuracy                           0.82       494\n",
      "   macro avg       0.80      0.69      0.72       494\n",
      "weighted avg       0.82      0.82      0.80       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inter_predictions = inter_prediction_model.predict(df_test[['type', 'site_name', 'authors']])\n",
    "print (classification_report(df_test['fake'], inter_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simplified model as shown above that makes an intermediate prediction based on just the 3 categorical features (non-textual matter) - authors, site_name, type. We will use this prediction as an input in the larger model which includes the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train inter_prediction_model on entire sub df\n",
    "inter_prediction_model = CategoricalNB().fit(df_sub[['type', 'site_name', 'authors']], df_sub['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      7582\n",
      "        True       0.76      0.48      0.58      2446\n",
      "\n",
      "    accuracy                           0.84     10028\n",
      "   macro avg       0.80      0.71      0.74     10028\n",
      "weighted avg       0.83      0.84      0.82     10028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply on the main df\n",
    "inter_predictions = inter_prediction_model.predict(df_main[['type', 'site_name', 'authors']])\n",
    "print (classification_report(df_main['fake'], inter_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_predictions=pd.Series(inter_predictions).astype('float64')\n",
    "inter_predictions=inter_predictions*2000 # for boosting weight\n",
    "df_main=pd.concat([df_main.reset_index(drop=True),inter_predictions.rename('inter_predictions').reset_index(drop=True)],axis=1)\n",
    "# renamed series otherwise will take a default name like 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_main, test_size=0.2, random_state=149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sub_features = df_train[['inter_predictions']].copy()\n",
    "df_test_sub_features = df_test[['inter_predictions']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running above step, everything below is similar to C1 to C5. You can even run all the C1 to C5 now to see the effect of sub prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_title_tfidf = get_tfidf(df_train['normal_title'])\n",
    "df_train_normal_title_tfidf = pd.DataFrame(normal_title_tfidf['text_tfidf'].toarray())\n",
    "\n",
    "df_train_C2 = pd.concat([df_train_normal_title_tfidf.reset_index(drop=True), df_train_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_train_C2_sm=scipy.sparse.csr_matrix(df_train_C2.values).copy() #sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_model = MultinomialNB().fit(df_train_C2_sm, df_train['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_title_bow = normal_title_tfidf['bow_transformer'].transform(df_test['normal_title'].apply(' '.join))\n",
    "test_normal_title_tfidf = normal_title_tfidf['tfidf_transformer'].transform(test_normal_title_bow)\n",
    "df_test_normal_title_tfidf = pd.DataFrame(test_normal_title_tfidf.toarray())\n",
    "\n",
    "df_test_C2 = pd.concat([df_test_normal_title_tfidf.reset_index(drop=True), df_test_sub_features.reset_index(drop=True)], ignore_index=True, sort=False, axis = 1)\n",
    "df_test_C2_sm=scipy.sparse.csr_matrix(df_test_C2.values).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.95      0.90      1535\n",
      "        True       0.74      0.44      0.55       471\n",
      "\n",
      "    accuracy                           0.83      2006\n",
      "   macro avg       0.79      0.69      0.72      2006\n",
      "weighted avg       0.82      0.83      0.81      2006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = fakenews_model.predict(df_test_C2_sm)\n",
    "print (classification_report(df_test['fake'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
